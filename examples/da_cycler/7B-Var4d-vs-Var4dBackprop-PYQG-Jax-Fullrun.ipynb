{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dabench as dab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f7381",
   "metadata": {},
   "source": [
    "# Read-in Raytune Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12353733",
   "metadata": {},
   "outputs": [],
   "source": [
    "raytune_system_dim_results = pd.read_csv('./pyqg_jax_raytune_sgdopt_werrors_v10_10epochs_system_dims_16_20_24_32.csv')\n",
    "raytune_system_dim_results['trialnum'] = raytune_system_dim_results.index\n",
    "raytune_system_dim_results.index = np.arange(raytune_system_dim_results.shape[0])\n",
    "rows_to_get = raytune_system_dim_results.groupby(['system_dim_xy']).idxmin(numeric_only=True)['rmse']\n",
    "best_results_system_dim = raytune_system_dim_results.loc[rows_to_get]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10df40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_system_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e854ed",
   "metadata": {},
   "source": [
    "# Define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0661957",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_in_timesteps = 4380\n",
    "spinup_size = 5*year_in_timesteps\n",
    "valid_size = round(year_in_timesteps/4)\n",
    "transient_size = 1*year_in_timesteps\n",
    "test_size = 1*year_in_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37957505",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_steps = spinup_size + valid_size + transient_size + test_size\n",
    "delta_t=7200\n",
    "analysis_window = 6*delta_t\n",
    "analysis_time_in_window = 3*delta_t\n",
    "num_epochs = 10\n",
    "n_outer_loops = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799cc91",
   "metadata": {},
   "source": [
    "# Function for running 4DVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_4dvar(system_dim_xy, nr_steps, spinup_size, valid_size, test_size, test_run, delta_t,\n",
    "              sigma_bg_multiplier, sigma_obs_multiplier, analysis_window, analysis_time_in_window,\n",
    "              random_seed, n_outer_loops):\n",
    "    np_rng = np.random.default_rng(random_seed)\n",
    "    jax.clear_backends()\n",
    "\n",
    "\n",
    "    ### Nature Run\n",
    "    nature_run = dab.data.PyQGJax(nx=system_dim_xy, ny=system_dim_xy, delta_t=delta_t, store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    nature_run.generate(n_steps=nr_steps) \n",
    "    nr_spinup, nr_valid, nr_transient_and_test = nature_run.split_train_valid_test(\n",
    "        spinup_size, valid_size, transient_size + test_size)\n",
    "    nr_transient, nr_test, _ = nr_transient_and_test.split_train_valid_test(transient_size, test_size, 0)\n",
    "\n",
    "    if not test_run:\n",
    "        nr_eval = nr_valid\n",
    "    else:\n",
    "        nr_eval = nr_test\n",
    "        \n",
    "    ### Observations\n",
    "    obs_location_count = round(nature_run.system_dim/2)\n",
    "\n",
    "    # First we need to calculate the per-variable SD for QGS model\n",
    "    obs_sd_scale = 0.1\n",
    "    per_variable_sd = np.std(nr_spinup.values, axis=0)\n",
    "    obs_sd = 0.1*per_variable_sd\n",
    "\n",
    "    obs_pyqg = dab.observer.Observer(\n",
    "        nr_eval, # Data generator object\n",
    "        time_indices = np.arange(0, nr_eval.time_dim, 3), # Observation every other timestep\n",
    "        random_location_count = obs_location_count, # Probability of picking each location in l63.system_dim for random sampling\n",
    "        error_bias = 0.0, # Mean for observation error, Gaussian/Normal distribution\n",
    "        error_sd = obs_sd, # Standard deviation for observation error, Gaussian/Normal distribution\n",
    "        random_seed=random_seed+test_run, # We can specify a random seed. Default is 99\n",
    "        stationary_observers=True,\n",
    "        store_as_jax=True\n",
    "    )\n",
    "\n",
    "    obs_vec_pyqg = obs_pyqg.observe()\n",
    "\n",
    "    ### Model\n",
    "    model_pyqg = dab.data.PyQGJax(nx=system_dim_xy, ny=system_dim_xy, store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    class PyQGModel(dab.model.Model):                                                                       \n",
    "        \"\"\"Defines model wrapper for Lorenz96 to test forecasting.\"\"\"\n",
    "        def forecast(self, state_vec, n_steps):\n",
    "            gridded_values = state_vec.values.reshape(self.model_obj.original_dim)\n",
    "            self.model_obj.generate(x0=gridded_values, n_steps=n_steps)\n",
    "            new_vals = self.model_obj.values\n",
    "\n",
    "            new_vec = dab.vector.StateVector(values=new_vals, store_as_jax=True)\n",
    "\n",
    "            return new_vec\n",
    "\n",
    "        def _forecast_x0(self, x0, n_steps):\n",
    "            self.model_obj.generate(x0=x0.reshape(self.model_obj.original_dim), n_steps=n_steps)\n",
    "            return self.model_obj.values\n",
    "\n",
    "        def compute_tlm(self, state_vec, n_steps):\n",
    "            x0 = state_vec.values\n",
    "            return jax.jacrev(self._forecast_x0, argnums=0)(x0, n_steps), self._forecast_x0(x0, n_steps)\n",
    "\n",
    "    fc_model = PyQGModel(model_obj=model_pyqg)\n",
    "\n",
    "    \n",
    "    ### Set up DA matrices\n",
    "    sigma_obs=sigma_obs_multiplier*obs_sd[obs_vec_pyqg.location_indices[0]]\n",
    "    sigma_bg = sigma_bg_multiplier*obs_sd\n",
    "    H = np.zeros((obs_location_count, nature_run.system_dim))\n",
    "    H[np.arange(H.shape[0]), obs_vec_pyqg.location_indices[0]] = 1\n",
    "    R = (sigma_obs**2) * np.identity(obs_location_count)\n",
    "    B = (sigma_bg**2)*np.identity(nature_run.system_dim)\n",
    "    Bsqrt = np.sqrt(B)\n",
    "\n",
    "\n",
    "    da_time_start = timer()\n",
    "    \n",
    "    dc = dab.dacycler.Var4D(\n",
    "        system_dim=nature_run.system_dim,\n",
    "        delta_t=nr_eval.delta_t,\n",
    "        H=H,\n",
    "        B=B,\n",
    "        R=R,\n",
    "        n_outer_loops=n_outer_loops,\n",
    "        model_obj=fc_model,\n",
    "        obs_window_indices=[0,3,6],\n",
    "        steps_per_window=7, # 0 and 6 inclusive\n",
    "        )\n",
    "\n",
    "    \n",
    "    ### Execute\n",
    "    cur_tstep = 0\n",
    "    x0_original = nr_eval.values[cur_tstep] + np_rng.normal(size=(nature_run.system_dim,), scale=sigma_bg)\n",
    "\n",
    "    x0_sv = dab.vector.StateVector(\n",
    "        values=x0_original,\n",
    "        store_as_jax=True)\n",
    "    \n",
    "    out_statevec, losses = dc.cycle(\n",
    "        input_state = x0_sv,\n",
    "        start_time = nr_eval.times[cur_tstep],\n",
    "        obs_vector = obs_vec_pyqg,\n",
    "        analysis_window=analysis_window,\n",
    "        timesteps=int(nr_eval.time_dim/6) - 2,\n",
    "        obs_error_sd=sigma_obs,\n",
    "        analysis_time_in_window=analysis_time_in_window)\n",
    "    \n",
    "    da_time = timer()-da_time_start\n",
    "\n",
    "    rmse = np.sqrt(np.mean(np.square(nr_eval.values[:out_statevec.values.shape[0]] - out_statevec.values)))\n",
    "    \n",
    "    \n",
    "    return rmse, da_time, out_statevec, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063b9f1",
   "metadata": {},
   "source": [
    "# Function for running Backprop-4DVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_backprop_4dvar(system_dim_xy, nr_steps, spinup_size, valid_size, test_size, test_run, delta_t,\n",
    "              sigma_bg_multiplier, sigma_obs_multiplier, analysis_window, analysis_time_in_window,\n",
    "              random_seed, num_epochs, learning_rate, lr_decay):\n",
    "    np_rng = np.random.default_rng(random_seed)\n",
    "    jax.clear_backends()\n",
    "\n",
    "\n",
    "    ### Nature Run\n",
    "    nature_run = dab.data.PyQGJax(nx=system_dim_xy, ny=system_dim_xy, delta_t=delta_t, store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    nature_run.generate(n_steps=nr_steps) \n",
    "    nr_spinup, nr_valid, nr_transient_and_test = nature_run.split_train_valid_test(\n",
    "        spinup_size, valid_size, transient_size + test_size)\n",
    "    nr_transient, nr_test, _ = nr_transient_and_test.split_train_valid_test(transient_size, test_size, 0)\n",
    "\n",
    "    if not test_run:\n",
    "        nr_eval = nr_valid\n",
    "    else:\n",
    "        nr_eval = nr_test\n",
    "        \n",
    "    ### Observations\n",
    "    obs_location_count = round(nature_run.system_dim/2)\n",
    "\n",
    "    # First we need to calculate the per-variable SD for QGS model\n",
    "    obs_sd_scale = 0.1\n",
    "    per_variable_sd = np.std(nr_spinup.values, axis=0)\n",
    "    obs_sd = 0.1*per_variable_sd\n",
    "\n",
    "    obs_pyqg = dab.observer.Observer(\n",
    "        nr_eval, # Data generator object\n",
    "        time_indices = np.arange(0, nr_eval.time_dim, 3), # Observation every other timestep\n",
    "        random_location_count = obs_location_count, # Probability of picking each location in l63.system_dim for random sampling\n",
    "        error_bias = 0.0, # Mean for observation error, Gaussian/Normal distribution\n",
    "        error_sd = obs_sd, # Standard deviation for observation error, Gaussian/Normal distribution\n",
    "        random_seed=random_seed+test_run, # We can specify a random seed. Default is 99\n",
    "        stationary_observers=True,\n",
    "        store_as_jax=True\n",
    "    )\n",
    "\n",
    "    obs_vec_pyqg = obs_pyqg.observe()\n",
    "\n",
    "    ### Model\n",
    "    model_pyqg = dab.data.PyQGJax(nx=system_dim_xy, ny=system_dim_xy, store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    class PyQGModel(dab.model.Model):                                                                       \n",
    "        \"\"\"Defines model wrapper for Lorenz96 to test forecasting.\"\"\"\n",
    "        def forecast(self, state_vec, n_steps):\n",
    "            gridded_values = state_vec.values.reshape(self.model_obj.original_dim)\n",
    "            self.model_obj.generate(x0=gridded_values, n_steps=n_steps)\n",
    "            new_vals = self.model_obj.values\n",
    "\n",
    "            new_vec = dab.vector.StateVector(values=new_vals, store_as_jax=True)\n",
    "\n",
    "            return new_vec\n",
    "\n",
    "        def _forecast_x0(self, x0, n_steps):\n",
    "            self.model_obj.generate(x0=x0.reshape(self.model_obj.original_dim), n_steps=n_steps)\n",
    "            return self.model_obj.values\n",
    "\n",
    "        def compute_tlm(self, state_vec, n_steps):\n",
    "            x0 = state_vec.values\n",
    "            return jax.jacrev(self._forecast_x0, argnums=0)(x0, n_steps), self._forecast_x0(x0, n_steps)\n",
    "\n",
    "    fc_model = PyQGModel(model_obj=model_pyqg)\n",
    "\n",
    "    \n",
    "    ### Set up DA matrices    \n",
    "    obs_total_size = int(obs_location_count*3)\n",
    "    sigma_obs=sigma_obs_multiplier*np.tile(obs_sd[obs_vec_pyqg.location_indices[0]], 3)\n",
    "    sigma_bg = sigma_bg_multiplier*obs_sd\n",
    "    H = np.zeros((obs_location_count, nature_run.system_dim))\n",
    "    H[np.arange(H.shape[0]), np.tile(obs_vec_pyqg.location_indices[0], 1)] = 1\n",
    "    R = (sigma_obs**2)* np.identity(obs_total_size)\n",
    "    B = (sigma_bg**2)*np.identity(nature_run.system_dim)\n",
    "    Bsqrt = np.sqrt(B)\n",
    "\n",
    "    ### Set up DA Cycler\n",
    "    da_time_start = timer()\n",
    "    \n",
    "    dc = dab.dacycler.Var4DBackprop(\n",
    "        system_dim=nature_run.system_dim,\n",
    "        delta_t=nr_eval.delta_t,\n",
    "        H=H,\n",
    "        B=B,\n",
    "        R=R,\n",
    "        # These will be set later in run_backprop_4dvar\n",
    "        num_epochs=num_epochs, \n",
    "        learning_rate=learning_rate,\n",
    "        lr_decay=lr_decay,\n",
    "        model_obj=fc_model,\n",
    "        obs_window_indices=[0,3,6],\n",
    "        steps_per_window=7, # 7 instead of 6 because inclusive of 0 and 6\n",
    "        )\n",
    "    \n",
    "    ### Execute\n",
    "    cur_tstep = 0\n",
    "    x0_original = nr_eval.values[cur_tstep] + np_rng.normal(size=(nature_run.system_dim,), scale=sigma_bg)\n",
    "\n",
    "    x0_sv = dab.vector.StateVector(\n",
    "        values=x0_original,\n",
    "        store_as_jax=True)\n",
    "    \n",
    "\n",
    "    out_statevec, losses = dc.cycle(\n",
    "        input_state = x0_sv,\n",
    "        start_time = nr_eval.times[cur_tstep],\n",
    "        obs_vector = obs_vec_pyqg,\n",
    "        analysis_window=analysis_window,\n",
    "        timesteps=int(nr_eval.time_dim/6) - 2,\n",
    "        obs_error_sd=sigma_obs,\n",
    "        analysis_time_in_window=analysis_time_in_window)\n",
    "    \n",
    "    da_time = timer()-da_time_start\n",
    "    print(out_statevec, losses)\n",
    "\n",
    "    rmse = np.sqrt(np.mean(np.square(nr_eval.values[:out_statevec.values.shape[0]] - out_statevec.values)))\n",
    "    \n",
    "    return rmse, da_time, out_statevec, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074bd40",
   "metadata": {},
   "source": [
    "# Function for baserun without DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baserun(system_dim_xy, nr_steps, spinup_size, valid_size, test_size, test_run, delta_t,random_seed, sigma_bg_multiplier):\n",
    "    np_rng = np.random.default_rng(random_seed)\n",
    "    jax.clear_backends()\n",
    "\n",
    "\n",
    "    ### Nature Run\n",
    "    nature_run = dab.data.PyQGJax(nx=system_dim_xy, ny=system_dim_xy, delta_t=delta_t, store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    nature_run.generate(n_steps=nr_steps) \n",
    "    nr_spinup, nr_valid, nr_transient_and_test = nature_run.split_train_valid_test(\n",
    "        spinup_size, valid_size, transient_size + test_size)\n",
    "    nr_transient, nr_test, _ = nr_transient_and_test.split_train_valid_test(transient_size, test_size, 0)\n",
    "\n",
    "    if not test_run:\n",
    "        nr_eval = nr_valid\n",
    "    else:\n",
    "        nr_eval = nr_test\n",
    "        \n",
    "    # Calculate the per-variable SD for QGS model\n",
    "    obs_sd_scale = 0.1\n",
    "    per_variable_sd = np.std(nr_spinup.values, axis=0)\n",
    "    obs_sd = 0.1*per_variable_sd\n",
    "    sigma_bg = sigma_bg_multiplier*obs_sd\n",
    "\n",
    "\n",
    "    ### Model\n",
    "    model_pyqg = dab.data.PyQGJax(nx=system_dim_xy, ny=system_dim_xy, store_as_jax=True, random_seed=random_seed)\n",
    "    \n",
    "    ### Initial conditions\n",
    "    \n",
    "    ### Set up DA Cycler\n",
    "    da_time_start = timer()\n",
    "    \n",
    "    \n",
    "    cur_tstep = 0\n",
    "    x0_original = nr_eval.values[cur_tstep] + np_rng.normal(size=(nature_run.system_dim,), scale=sigma_bg)\n",
    "    x0_gridded = x0_original.reshape(nature_run.original_dim)\n",
    " \n",
    "    model_pyqg.generate(x0=x0_gridded, n_steps=nr_eval.time_dim)\n",
    "    rmse = np.sqrt(np.mean(np.square(model_pyqg.values[:-12] - nr_eval.values[:-12])))\n",
    "\n",
    "\n",
    "    da_time = timer()-da_time_start\n",
    "    \n",
    "    return rmse, da_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71737521",
   "metadata": {},
   "source": [
    "# Run DA for test period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd2c28",
   "metadata": {},
   "source": [
    "### Baserun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df_list_baserun = []\n",
    "system_dim_xy_list = [16, 20, 24, 32]\n",
    "test_run=True\n",
    "# Run\n",
    "for system_dim_xy in system_dim_xy_list:\n",
    "    random_seed = system_dim_xy\n",
    "    run_dict = dict(\n",
    "        system_dim_xy=system_dim_xy, \n",
    "        nr_steps=nr_steps,\n",
    "        spinup_size=spinup_size,\n",
    "        valid_size=valid_size,\n",
    "        test_size=test_size,\n",
    "        test_run=test_run,\n",
    "        delta_t=delta_t,\n",
    "        sigma_bg_multiplier=0.5,\n",
    "        random_seed=random_seed)\n",
    "    error_br, da_time = run_baserun(**run_dict)\n",
    "    out_df = pd.DataFrame(run_dict,index=[0])\n",
    "    out_df['rmse'] = error_br\n",
    "    out_df['da_time'] = da_time\n",
    "    print(error_br)\n",
    "    print(da_time)\n",
    "    all_results_df_list_baserun.append(out_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_out_df_baserun = pd.concat(all_results_df_list_baserun)\n",
    "print(full_out_df_baserun)\n",
    "full_out_df_baserun.to_csv('./out/pyqg_jax/pyqg_baserun_results_test_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3cb212",
   "metadata": {},
   "source": [
    "### 4Dvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df_list_4d = []\n",
    "all_statevecs_4d = []\n",
    "system_dim_xy_list = [16, 20, 24, 32]\n",
    "test_run=True\n",
    "# Run\n",
    "for system_dim_xy in system_dim_xy_list:\n",
    "    random_seed = system_dim_xy\n",
    "    run_dict = dict(\n",
    "        system_dim_xy=system_dim_xy, \n",
    "        nr_steps=nr_steps,\n",
    "        spinup_size=spinup_size,\n",
    "        valid_size=valid_size,\n",
    "        test_size=test_size,\n",
    "        test_run=test_run,\n",
    "        delta_t=delta_t,\n",
    "        sigma_bg_multiplier=0.5,\n",
    "        sigma_obs_multiplier=1.25,\n",
    "        analysis_window=analysis_window,\n",
    "        analysis_time_in_window=analysis_time_in_window,\n",
    "        random_seed=random_seed,\n",
    "        n_outer_loops=n_outer_loops)\n",
    "    error_4d, da_time, out_sv, loss_vals = run_4dvar(**run_dict)\n",
    "    out_df = pd.DataFrame(run_dict,index=[0])\n",
    "    out_df['rmse'] = error_4d\n",
    "    out_df['da_time'] = da_time\n",
    "    print(error_4d)\n",
    "    print(da_time)\n",
    "    all_results_df_list_4d.append(out_df)\n",
    "    all_statevecs_4d.append(out_sv)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_out_df_4d = pd.concat(all_results_df_list_4d)\n",
    "print(full_out_df_4d)\n",
    "full_out_df_4d.to_csv('./out/pyqg_jax/pyqg_4dvar_results_test_v2_sysdimxy_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88686a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(full_out_df_4d.shape[0]):\n",
    "    sysdimxy = full_out_df_4d['system_dim_xy'].values[i]\n",
    "    out_file = './out/pyqg_jax/pyqg_4dvar_results_sysdimxy_{}.pkl'.format(sysdimxy)\n",
    "    out_vec = all_statevecs_4d[i]\n",
    "    \n",
    "    with open(out_file, 'wb') as f:  # open a text file\n",
    "         pickle.dump(out_vec, f) # serialize the list\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rmse_df_list = []\n",
    "full_df_20_24 = pd.read_csv('./out/pyqg_jax/pyqg_4dvar_results_test_v2_sysdimxy_20_24.csv')\n",
    "full_df_32 = pd.read_csv('./out/pyqg_jax/pyqg_4dvar_results_test_v2_sysdimxy_32_fullyear.csv')\n",
    "temp_df_16 = pd.DataFrame({'rmse':[2.401127956217721e-7],\n",
    "                           'da_time': [2827.1763451290026],\n",
    "                           'system_dim_xy': [16]})\n",
    "full_rmse_df_list.append(temp_df_16)\n",
    "full_rmse_df_list.append(full_df_20_24.loc[:, ['rmse','da_time', 'system_dim_xy']])\n",
    "full_rmse_df_list.append(full_df_32.loc[:, ['rmse','da_time', 'system_dim_xy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(full_rmse_df_list).to_csv('./out/pyqg_jax/pyqg_4dvar_results_test_v2_sysdimxy_all_fullyear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762e873",
   "metadata": {},
   "source": [
    "### Backprop-4DVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbe405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_results_df_list_bp = []\n",
    "all_statevecs_bp = []\n",
    "all_losses_bp = []\n",
    "system_dim_xy_list = [16, 20, 24, 32]\n",
    "test_run=True\n",
    "# Run\n",
    "for system_dim_xy in system_dim_xy_list:\n",
    "    random_seed=system_dim_xy\n",
    "    raytune_results = best_results_system_dim.loc[best_results_system_dim['system_dim_xy']==system_dim_xy]\n",
    "    test_size = year_in_timesteps\n",
    "    lr = raytune_results['config/lr'].values[0]\n",
    "    lr_decay = raytune_results['config/lr_decay'].values[0]\n",
    "    run_dict = dict(\n",
    "        system_dim_xy=system_dim_xy, \n",
    "        nr_steps=nr_steps,\n",
    "        spinup_size=spinup_size,\n",
    "        valid_size=valid_size,\n",
    "        test_size=test_size,\n",
    "        test_run=test_run,\n",
    "        delta_t=delta_t,\n",
    "        sigma_bg_multiplier=0.5,\n",
    "        sigma_obs_multiplier=1.25,\n",
    "        analysis_window=analysis_window,\n",
    "        analysis_time_in_window=analysis_time_in_window,\n",
    "        random_seed=random_seed,\n",
    "        num_epochs=num_epochs,\n",
    "        learning_rate=lr,\n",
    "        lr_decay=lr_decay)\n",
    "    error_bp, da_time, out_sv, out_losses = run_backprop_4dvar(**run_dict)\n",
    "    out_df = pd.DataFrame(run_dict,index=[0])\n",
    "    out_df['rmse'] = error_bp\n",
    "    out_df['da_time'] = da_time\n",
    "    all_results_df_list_bp.append(out_df)\n",
    "    all_statevecs_bp.append(out_sv)\n",
    "    all_losses_bp.append(out_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_out_df_bp = pd.concat(all_results_df_list_bp)\n",
    "full_out_df_bp.to_csv('./out/pyqg_jax/pyqg_4dvar_results_test_v5_25epochs_dim32fullyear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_out_df_bp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dab-pyqg-jax",
   "language": "python",
   "name": "dab-pyqg-jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
