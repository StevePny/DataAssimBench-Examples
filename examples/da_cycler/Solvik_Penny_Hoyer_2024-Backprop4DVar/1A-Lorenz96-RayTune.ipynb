{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dabench as dab\n",
    "import numpy as np\n",
    "import jax\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "\n",
    "from ray import train, tune\n",
    "from hyperopt import hp\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c64ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p out/l96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e854ed",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_dim= 36\n",
    "spinup_size = 14400\n",
    "valid_size = 5000\n",
    "test_size = 5000\n",
    "nr_steps = spinup_size + valid_size + test_size\n",
    "delta_t=0.01\n",
    "obs_sd = 0.5\n",
    "sigma_bg = 0.3\n",
    "sigma_obs = 0.625\n",
    "analysis_window = 0.1\n",
    "analysis_time_in_window = 0.05\n",
    "obs_location_count = 18\n",
    "random_seed = 5\n",
    "num_iters = 3\n",
    "n_outer_loops = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063b9f1",
   "metadata": {},
   "source": [
    "# Function definition: Backprop 4DVar\n",
    "\n",
    "We'll need to prep and run Backprop-4DVar many times, so this wraps it all into one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873bf6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_backprop_4dvar(system_dim, nr_steps, spinup_size, valid_size, test_size, \n",
    "                       test_run, delta_t, obs_location_count, obs_sd, sigma_bg, \n",
    "                       sigma_obs, analysis_window, analysis_time_in_window, \n",
    "                       random_seed, num_iters, learning_rate, lr_decay):\n",
    "    np_rng = np.random.default_rng(random_seed)\n",
    "    jax.clear_caches()\n",
    "\n",
    "    ### Nature Run\n",
    "    nature_run = dab.data.Lorenz96(system_dim=system_dim, delta_t=delta_t,\n",
    "                                   store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    x0_initial = np_rng.normal(size=system_dim, scale=1)\n",
    "    nature_run.generate(n_steps=nr_steps, x0 = x0_initial) \n",
    "    nr_spinup, nr_valid, nr_test = nature_run.split_train_valid_test(\n",
    "        spinup_size, valid_size, test_size)\n",
    "\n",
    "    if not test_run:\n",
    "        nr_eval = nr_valid\n",
    "    else:\n",
    "        nr_eval = nr_test\n",
    "\n",
    "\n",
    "    ### Observations\n",
    "    obs_l96 = dab.observer.Observer(\n",
    "        nr_eval,\n",
    "        time_indices = np.arange(0, nr_eval.time_dim, 5),\n",
    "        random_location_count = obs_location_count,\n",
    "        error_bias = 0.0,\n",
    "        error_sd = obs_sd,\n",
    "        random_seed=random_seed,\n",
    "        stationary_observers=True,\n",
    "        store_as_jax=True\n",
    "    )\n",
    "    obs_vec_l96 = obs_l96.observe()\n",
    "\n",
    "    \n",
    "    ### Forecast Model\n",
    "    model_l96 = dab.data.Lorenz96(system_dim=system_dim, delta_t=delta_t, \n",
    "                                  store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    class L96Model(dab.model.Model):                                                                       \n",
    "        \"\"\"Defines model wrapper for Lorenz96 to test forecasting.\"\"\"\n",
    "        def forecast(self, state_vec, n_steps):\n",
    "            self.model_obj.generate(x0=state_vec.values, n_steps=n_steps)\n",
    "            new_vals = self.model_obj.values \n",
    "\n",
    "            new_vec = dab.vector.StateVector(values=new_vals, store_as_jax=True)\n",
    "\n",
    "            return new_vec\n",
    "\n",
    "    fc_model = L96Model(model_obj=model_l96)\n",
    "    \n",
    "    ### Set up DA matrices: H (observation), R (obs error), B (background error)\n",
    "    H = np.zeros((obs_location_count, system_dim))\n",
    "    H[np.arange(H.shape[0]), obs_vec_l96.location_indices[0]] = 1\n",
    "    R = (sigma_obs**2)* np.identity(obs_location_count)\n",
    "    B = (sigma_bg**2)*np.identity(system_dim)\n",
    "\n",
    "    \n",
    "    ### Run data assimilation\n",
    "    da_time_start = timer()\n",
    "    \n",
    "    # Prep DA object\n",
    "    dc = dab.dacycler.Var4DBackprop(\n",
    "        system_dim=system_dim,\n",
    "        delta_t=nr_eval.delta_t,\n",
    "        H=H,\n",
    "        B=B,\n",
    "        R=R,\n",
    "        num_iters=num_iters,\n",
    "        loss_growth_limit=5,\n",
    "        learning_rate=learning_rate,\n",
    "        lr_decay=lr_decay,\n",
    "        model_obj=fc_model,\n",
    "        obs_window_indices=[0,5,10],\n",
    "        steps_per_window=11, # 11 instead of 10 because inclusive of 0 and 11\n",
    "        )\n",
    "\n",
    "    # Generate initial conditions\n",
    "    cur_tstep = 0\n",
    "    x0_original = nr_eval.values[cur_tstep] + np_rng.normal(size=(system_dim,), \n",
    "                                                            scale=1)\n",
    "    x0_sv = dab.vector.StateVector(\n",
    "        values=x0_original,\n",
    "        store_as_jax=True)\n",
    "    \n",
    "    # Execute\n",
    "    out_statevec = dc.cycle(\n",
    "        input_state = x0_sv,\n",
    "        start_time = nr_eval.times[cur_tstep],\n",
    "        obs_vector = obs_vec_l96,\n",
    "        analysis_window=analysis_window,\n",
    "        timesteps=498,\n",
    "        obs_error_sd=sigma_obs,\n",
    "        analysis_time_in_window=analysis_time_in_window)\n",
    "    \n",
    "    da_time = timer()-da_time_start\n",
    "    rmse = np.sqrt(np.mean(np.square(nr_eval.values[:-20] - out_statevec.values)))\n",
    "    \n",
    "    return out_statevec, rmse, obs_vec_l96, nr_eval, da_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9304a47",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization on validation set\n",
    "\n",
    "Using RayTune to optimize alpha (learning rate) and alpha decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_backprop_4dvar(config, system_dim, num_obs, obs_sd):\n",
    "    \"\"\"A wrapper for RayTune to run backprop 4Dvar\"\"\"\n",
    "    random_seed = system_dim \n",
    "    obs_location_count = num_obs\n",
    "    run_dict = dict(\n",
    "        system_dim=system_dim, \n",
    "        nr_steps=nr_steps,\n",
    "        spinup_size=spinup_size,\n",
    "        valid_size=valid_size,\n",
    "        test_size=test_size,\n",
    "        test_run=False,\n",
    "        delta_t=delta_t,\n",
    "        obs_location_count=obs_location_count,\n",
    "        obs_sd=obs_sd,\n",
    "        sigma_bg=obs_sd/1.5,\n",
    "        sigma_obs=obs_sd*1.25,\n",
    "        analysis_window=analysis_window,\n",
    "        analysis_time_in_window=analysis_time_in_window,\n",
    "        random_seed=random_seed,\n",
    "        num_iters=num_iters,\n",
    "        learning_rate=0,\n",
    "        lr_decay = 0)\n",
    "\n",
    "    run_dict['learning_rate'] = config['lr']\n",
    "    run_dict['lr_decay'] = config['lr_decay']\n",
    "    \n",
    "    out_bp, error_bp, obs_vec_l96, nr_eval, da_time = run_backprop_4dvar(**run_dict)\n",
    "    \n",
    "    train.report({'rmse':error_bp})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec0ffa",
   "metadata": {},
   "source": [
    "### System size experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space\n",
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", -5, 0),\n",
    "    \"lr_decay\": hp.uniform(\"lr_decay\", 0.1, 0.99),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe46d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_results_df_list = []\n",
    "system_dim_list = [6, 20, 36, 72, 144, 256]\n",
    "\n",
    "for system_dim in system_dim_list:\n",
    "    tune_time_start = timer()\n",
    "    \n",
    "    trainable_with_system_dim = tune.with_parameters(train_backprop_4dvar, \n",
    "                                                     system_dim=system_dim,\n",
    "                                                     num_obs=int(system_dim/2),\n",
    "                                                     obs_sd=0.5\n",
    "                                                     )\n",
    "    \n",
    "    hyperopt_search = HyperOptSearch(space, metric=\"rmse\", mode=\"min\",\n",
    "                                     random_state_seed=22+system_dim)\n",
    "    tuner = tune.Tuner(\n",
    "        trainable_with_system_dim,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            num_samples=50,\n",
    "            max_concurrent_trials=4,\n",
    "            search_alg=hyperopt_search,\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    results = tuner.fit()\n",
    "\n",
    "    cur_results_df = results.get_dataframe()\n",
    "    cur_results_df['system_dim'] = system_dim\n",
    "    tune_time = timer() - tune_time_start\n",
    "    cur_results_df['total_tune_time'] = tune_time\n",
    "\n",
    "    all_results_df_list.append(cur_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d86181",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = pd.concat(all_results_df_list)\n",
    "full_results_df.to_csv('./out/l96/raytune_l96_hessian_v6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa3e37",
   "metadata": {},
   "source": [
    "### Experiments varying number of observations and obs error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a293f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", -5, 0),\n",
    "    \"lr_decay\": hp.uniform(\"lr_decay\", 0.1, 0.99),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295bcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_df_list = []\n",
    "\n",
    "system_dim = 36\n",
    "num_obs_list = [6, 12, 18, 24, 30, 36]\n",
    "obs_error_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1.0, 1.5, 2.0]\n",
    "\n",
    "for obs_location_count in num_obs_list:\n",
    "    for obs_i, obs_sd in enumerate(obs_error_list):\n",
    "        tune_time_start = timer()\n",
    "        \n",
    "        trainable_with_system_dim = tune.with_parameters(train_backprop_4dvar, \n",
    "                                                         system_dim=system_dim,\n",
    "                                                         num_obs=obs_location_count,\n",
    "                                                         obs_sd=obs_sd\n",
    "                                                         )\n",
    "\n",
    "        hyperopt_search = HyperOptSearch(space, metric=\"rmse\", mode=\"min\",\n",
    "                                         random_state_seed=22+obs_location_count+obs_i)\n",
    "        tuner = tune.Tuner(\n",
    "            trainable_with_system_dim,\n",
    "            tune_config=tune.TuneConfig(\n",
    "                num_samples=20,\n",
    "                max_concurrent_trials=4,\n",
    "                search_alg=hyperopt_search,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        results = tuner.fit()\n",
    "\n",
    "        cur_results_df = results.get_dataframe()\n",
    "        cur_results_df['system_dim'] = system_dim\n",
    "        cur_results_df['num_obs'] = obs_location_count\n",
    "        cur_results_df['obs_sd'] = obs_sd\n",
    "        tune_time = timer() - tune_time_start\n",
    "        cur_results_df['total_tune_time'] = tune_time\n",
    "        \n",
    "        all_results_df_list.append(cur_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab57eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = pd.concat(all_results_df_list)\n",
    "full_results_df.to_csv('./out/l96/raytune_werrors_heatmap_hessian_v5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
