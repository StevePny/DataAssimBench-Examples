{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dabench as dab\n",
    "import numpy as np\n",
    "import jax\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "import jaxlib\n",
    "\n",
    "from ray import train, tune\n",
    "from hyperopt import hp\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e854ed",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cbce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_in_timesteps = 4380\n",
    "spinup_size = 5*year_in_timesteps\n",
    "valid_size = round(year_in_timesteps/4)\n",
    "transient_size = 1*year_in_timesteps\n",
    "test_size = 1*year_in_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_steps = spinup_size + valid_size + transient_size + test_size\n",
    "delta_t=7200\n",
    "analysis_window = 6*delta_t\n",
    "analysis_time_in_window = 3*delta_t\n",
    "num_iters = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7063b9f1",
   "metadata": {},
   "source": [
    "### Function definition: Backprop 4DVar\n",
    "\n",
    "We'll need to prep and run Backprop-4DVar many times, so this wraps it all into functions.\n",
    "\n",
    "Note: Since we're using raytune, we're separating this into a prep function and a run function to speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f722ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_backprop_4dvar(system_dim_xy, nr_steps, spinup_size, valid_size, test_size,\n",
    "                        test_run, delta_t, sigma_bg_multiplier, sigma_obs_multiplier, \n",
    "                        random_seed):\n",
    "    \n",
    "    np_rng = np.random.default_rng(random_seed)\n",
    "    jax.clear_backends()\n",
    "\n",
    "    \n",
    "    ### Nature Run\n",
    "    nature_run = dab.data.PyQGJax(nx=system_dim_xy, ny=system_dim_xy, delta_t=delta_t, \n",
    "                                  store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    nature_run.generate(n_steps=nr_steps) \n",
    "    nr_spinup, nr_valid, nr_transient_and_test = nature_run.split_train_valid_test(\n",
    "        spinup_size, valid_size, transient_size + test_size)\n",
    "    nr_transient, nr_test, _ = nr_transient_and_test.split_train_valid_test(\n",
    "        transient_size, test_size, 0)\n",
    "\n",
    "    if not test_run:\n",
    "        nr_eval = nr_valid\n",
    "    else:\n",
    "        nr_eval = nr_test\n",
    "        \n",
    "        \n",
    "    ### Observations\n",
    "    obs_location_count = round(nature_run.system_dim/2)\n",
    "\n",
    "    # First we need to calculate the per-variable SD for QGS model\n",
    "    obs_sd_scale = 0.1\n",
    "    per_variable_sd = np.std(nr_spinup.values, axis=0)\n",
    "    obs_sd = 0.1*per_variable_sd\n",
    "\n",
    "    obs_pyqg = dab.observer.Observer(\n",
    "        nr_eval,\n",
    "        time_indices = np.arange(0, nr_eval.time_dim, 3),\n",
    "        random_location_count = obs_location_count,\n",
    "        error_bias = 0.0,\n",
    "        error_sd = obs_sd,\n",
    "        random_seed=random_seed+test_run,\n",
    "        stationary_observers=True,\n",
    "        store_as_jax=True\n",
    "    )\n",
    "\n",
    "    obs_vec_pyqg = obs_pyqg.observe()\n",
    "\n",
    "    \n",
    "    ### Forecast Model\n",
    "    model_pyqg = dab.data.PyQGJax(nx=system_dim_xy, ny=system_dim_xy,\n",
    "                                  store_as_jax=True, random_seed=random_seed)\n",
    "\n",
    "    class PyQGModel(dab.model.Model):                                                                       \n",
    "        \"\"\"Defines model wrapper for forecasting.\"\"\"\n",
    "        def forecast(self, state_vec, n_steps):\n",
    "            gridded_values = state_vec.values.reshape(self.model_obj.original_dim)\n",
    "            self.model_obj.generate(x0=gridded_values, n_steps=n_steps)\n",
    "            new_vals = self.model_obj.values\n",
    "\n",
    "            new_vec = dab.vector.StateVector(values=new_vals, store_as_jax=True)\n",
    "\n",
    "            return new_vec\n",
    "\n",
    "        def _forecast_x0(self, x0, n_steps):\n",
    "            self.model_obj.generate(x0=x0.reshape(self.model_obj.original_dim),\n",
    "                                    n_steps=n_steps)\n",
    "            return self.model_obj.values\n",
    "        \n",
    "    fc_model = PyQGModel(model_obj=model_pyqg)\n",
    "\n",
    "    \n",
    "    ### Set up DA matrices: H (observation), R (obs error), B (background error)\n",
    "    sigma_obs=sigma_obs_multiplier*obs_sd[obs_vec_pyqg.location_indices[0]]\n",
    "    sigma_bg = sigma_bg_multiplier*obs_sd\n",
    "    H = np.zeros((obs_location_count, nature_run.system_dim))\n",
    "    H[np.arange(H.shape[0]), obs_vec_pyqg.location_indices[0]] = 1\n",
    "    R = (sigma_obs**2) * np.identity(obs_location_count)\n",
    "    B = (sigma_bg**2)*np.identity(nature_run.system_dim)\n",
    "    \n",
    "    \n",
    "    ### Prep DA    \n",
    "    dc = dab.dacycler.Var4DBackprop(\n",
    "        system_dim=nature_run.system_dim,\n",
    "        delta_t=nr_eval.delta_t,\n",
    "        H=H,\n",
    "        B=B,\n",
    "        R=R,\n",
    "        # These will be set later in run_backprop_4dvar\n",
    "        num_iters=None, \n",
    "        learning_rate=None,\n",
    "        lr_decay=None,\n",
    "        model_obj=fc_model,\n",
    "        obs_window_indices=[0,3,6],\n",
    "        steps_per_window=7, # 7 instead of 6 because inclusive of 0 and 6\n",
    "        )\n",
    "    \n",
    "    # Generate initial conditions\n",
    "    cur_tstep = 0\n",
    "    x0_original = nr_eval.values[cur_tstep] + np_rng.normal(size=(nature_run.system_dim,),\n",
    "                                                            scale=sigma_bg)\n",
    "    x0_sv = dab.vector.StateVector(\n",
    "        values=x0_original,\n",
    "        store_as_jax=True)\n",
    "    start_time = nr_eval.times[cur_tstep]\n",
    "    \n",
    "    # Return necessary objects for running DA with different LR/LR Decay\n",
    "    return dc, x0_sv, start_time, obs_vec_pyqg, nr_eval, sigma_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873bf6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_backprop_4dvar(config, dc, x0_sv, start_time, obs_vec, nr_eval,\n",
    "                       sigma_obs, analysis_window, analysis_time_in_window,\n",
    "                       num_iters):\n",
    "    \n",
    "    dc.learning_rate = config['lr']\n",
    "    dc.lr_decay = config['lr_decay']\n",
    "    dc.num_iters = num_iters\n",
    "    \n",
    "    try: \n",
    "        out_statevec = dc.cycle(\n",
    "            input_state = x0_sv,\n",
    "            start_time = start_time,\n",
    "            obs_vector = obs_vec,\n",
    "            analysis_window=analysis_window,\n",
    "            timesteps=int(nr_eval.time_dim/6) - 2,\n",
    "            obs_error_sd=sigma_obs,\n",
    "            analysis_time_in_window=analysis_time_in_window)\n",
    "\n",
    "        rmse = np.sqrt(np.mean(np.square(\n",
    "            nr_eval.values[:out_statevec.values.shape[0]] - out_statevec.values\n",
    "        )))\n",
    "        train.report({'rmse':rmse})\n",
    "        \n",
    "    # Catch problem with exploding gradients\n",
    "    except jaxlib.xla_extension.XlaRuntimeError:\n",
    "        train.report({'rmse':999999})\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9304a47",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization on validation set\n",
    "\n",
    "Using RayTune to optimize alpha (learning rate) and alpha decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", -5, 0),\n",
    "    \"lr_decay\": hp.uniform(\"lr_decay\", 0.1, 0.99),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe46d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_results_df_list = []\n",
    "system_dim_xy_list = [16, 24, 32]\n",
    "\n",
    "for system_dim_xy in system_dim_xy_list:\n",
    "    tune_time_start = timer()\n",
    "\n",
    "    random_seed = system_dim_xy\n",
    "    \n",
    "    # Run prep\n",
    "    run_dict = dict(\n",
    "        system_dim_xy=system_dim_xy, \n",
    "        nr_steps=nr_steps,\n",
    "        spinup_size=spinup_size,\n",
    "        valid_size=valid_size,\n",
    "        test_size=test_size,\n",
    "        test_run=False,\n",
    "        delta_t=delta_t,\n",
    "        sigma_bg_multiplier=0.5,\n",
    "        sigma_obs_multiplier=1.25,\n",
    "        random_seed=random_seed)\n",
    "    dc, x0_sv, start_time, obs_vec, nr_eval, sigma_obs = prep_backprop_4dvar(**run_dict)\n",
    "    \n",
    "    \n",
    "    print('Starting... {} system dim'.format(system_dim_xy))\n",
    "    trainable_with_system_dim = tune.with_parameters(\n",
    "        run_backprop_4dvar, \n",
    "        dc=dc,\n",
    "        x0_sv=x0_sv,\n",
    "        start_time=start_time,\n",
    "        obs_vec=obs_vec,\n",
    "        nr_eval=nr_eval,\n",
    "        sigma_obs=sigma_obs, \n",
    "        analysis_window=analysis_window,\n",
    "        analysis_time_in_window=analysis_time_in_window,\n",
    "        num_iters=num_iters\n",
    "    )\n",
    "    \n",
    "    hyperopt_search = HyperOptSearch(space, metric=\"rmse\", mode=\"min\",\n",
    "                                     random_state_seed=22+system_dim_xy)\n",
    "    \n",
    "    # Run tuner\n",
    "    tuner = tune.Tuner(\n",
    "        trainable_with_system_dim,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            num_samples=50,\n",
    "            max_concurrent_trials=4,\n",
    "            search_alg=hyperopt_search,\n",
    "        ),\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "\n",
    "    cur_results_df = results.get_dataframe()\n",
    "\n",
    "    cur_results_df['system_dim_xy'] = system_dim_xy\n",
    "    \n",
    "    tune_time = timer() - tune_time_start\n",
    "    \n",
    "    cur_results_df['total_tune_time'] = tune_time\n",
    "\n",
    "    all_results_df_list.append(cur_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d86181",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = pd.concat(all_results_df_list)\n",
    "full_results_df.to_csv('./out/pyqg_jax/pyqg_jax_raytune_sgdopt_werrors_v15_hessian_approx_3epochs_system_dims_16_24_32_smallsearch.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dab-pyqg-jax",
   "language": "python",
   "name": "dab-pyqg-jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
